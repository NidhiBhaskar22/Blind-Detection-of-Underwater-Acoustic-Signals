# -*- coding: utf-8 -*-
"""UWACMain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Y0ytLoHSm3A4rXi58vsfd-y0J4oJ6sK
"""

import librosa
import librosa.display
import IPython.display as ipd
import resampy

!pip install resampy

import pandas as pd
audio_dataset_path='DeepShip-main/'
metadata=pd.read_csv('shipsEar.csv')
metadata.head()

import csv
with open('shipsEar.csv') as file_obj:

  heading=next(file_obj)

  reader_obj=csv.reader(file_obj)

  #for row in reader_obj:
    #print(row[3])

metadata['Type'].value_counts()

from google.colab import drive
drive.mount('/content/gdrive')

!unzip gdrive/My\ Drive/shipsear/shipsEar_AUDIOS-20230210T141200Z-001.zip

"""SAMPLING OF AUDIO SIGNAL"""

def features_extractor(file):
  audio, sample_rate=librosa.load(file,res_type='kaiser_fast')
  mfccs_features=librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)
  mfccs_scaled_features=np.mean(mfccs_features.T,axis=0)
  return mfccs_scaled_features

extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])
extracted_features_df.head()

X=np.array(extracted_features_df['feature'].tolist())
y=np.array(extracted_features_df['class'].tolist())

y=np.array(pd.get_dummies(y))

X.shape

y.shape

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

X_train

X_train.shape

X_test.shape

y_train

y_test.shape

"""MODEL Creation"""

import tensorflow as tf
from keras.layers import concatenate, Flatten, Dense, ConvLSTM2D, Dropout, Conv3D
from keras.models import Model
from keras.layers import Input, BatchNormalization, Reshape
from keras.callbacks import ModelCheckpoint

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten
from tensorflow.keras.optimizers import Adam
from sklearn import metrics

num_labels=y.shape[1]

model=Sequential()
###first layer
model.add(Dense(100,input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))
###second layer
model.add(Dense(200))
model.add(Activation('relu'))
model.add(Dropout(0.5))
###third layer
model.add(Dense(100))
model.add(Activation('relu'))
model.add(Dropout(0.5))

###final layer
model.add(Dense(num_labels))
model.add(Activation('softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')

from tensorflow.keras.callbacks import ModelCheckpoint
from datetime import datetime

num_epochs=50
num_batch_size=32

checkpointer=ModelCheckpoint(filepath='saved_model/audio_classification.hdf5',verbose=1,save_best_only=True)
start=datetime.now()

model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs,validation_data=(X_test,y_test), callbacks=[checkpointer])

duration= datetime.now()-start
print("Training completed in time: ",duration)

test_accuracy=model.evaluate(X_test,y_test,verbose=0)
print(test_accuracy[1])

filename="DeepShip-main/Cargo/15.wav"
prediction_feature=features_extractor(filename)
prediction_feature=prediction_feature.reshape(1,-1)
model.predict(prediction_feature)

from scipy.io import wavfile as wav
wave_sample_rate, wave_audio=wav.read(filename)
wave_sample_rate